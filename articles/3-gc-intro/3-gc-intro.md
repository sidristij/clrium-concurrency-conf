# Управление памятью

Всем привет. Большое спасибо, что пришли сегодня на этот семинар. Для меня было приятной неожиданностью получить sold-out, полный выкуп всех мест. Может, еще кто-то не пришел из-за других планов и решил остаться с видеозаписью. Но, тем не менее, это очень здорово. 

Меня зовут Станислав Сидристый. Я выступаю на разных конференциях время от времени. Занимаюсь разработкой под .NET. Когда-то пришел, полюбил и остался. На данный момент работаю в компании Epam Systems в Санкт-Петербурге. Где успешно, надеюсь, разрабатываю на ASP.NET. Иногда перехожу на C/C++. Иногда, совсем редко, исключительно для семинара, на C++/CLI. И, когда есть время, пишу свою книгу. Это «Архитектура платформы .NET». Она на русском языке, переводиться на английский профессиональным переводчиком - сам боюсь переводить - чтобы это можно было читать. И на китайский. Реалисты учат китайский. Можно пройти по ссылке, там все есть.

До сих пор мы все сидели на большой платформе .NET Framework.  Многие из нас и сейчас на ней сидят и, наверняка, долго еще будут. Когда я рассказывал на предыдущих докладах как работает Garbage Collector, то весь рассказ умещался ровно в один доклад и  зачатую мне задавали один вопрос: «Зачем это знать? Работает и работает». На уровне тех знаний, которые нам давали раньше и на собеседованиях, что обычно говорят: есть три поколения, два хипа больших и малых объектов. Еще максимум можно услышать про наличие неких сегментов и карточного стола. Но обычно дальше поколений и хипов люди не уходят. И все почему? Не потому, что чего-то не знают, а потому что действительно не понятно, зачем это знать.  Ведь та информация, которая нам давалась, выглядела как рекламный буклет к чему-то большому. Ну, знаем мы про три поколения. Теоретически, если забить второе поколение объектами нулевого, будет проблемы. Но это все какое-то эфемерное. 

Сейчас, когда Microsoft открыли исходники, я ожидал нескольких бенефитов от этого.   Первый бенефит - это то, что сообщество накинется и начнет какие-то баги исправлять. Оно накинулось. И исправило все грамматические ошибки в комментариях. Много запятых исправлено. Можно подать на членство в .NET  Foundation. Сейчас же можно, дорога открыта для граммар-наци. 

Второй бенефит - что найдутся заинтересованные люди. Понятное дело, что все туда лезть не будут. Во-первых, это достаточно сложно. Во-вторых, это много времени занимает. А времени у нас у всех не хватает. Все мы взрослые люди и, приходя домой, нам меньше всего хочется лезть в многотысячно-строчные файл C++ и что-то там изучать.  Была надежда, что туда придут люди увлеченные. Которые увлечены не только идеей изучать, но еще и идеей этим поделиться. И такие люди нашлись - Конрад Кокоса. Кто в курсе, что он написал книгу? Там в конце был список книг, очень рекомендую посмотреть.

Книга большая и текущий семинар - это пересказ ее второй половины. Потому частично вы с ней будете знакомы. Я надеялся, что эти люди начнут прокапывать, смотреть исходники, искать алгоритмы и понимать, как это все устроено, чтобы более подробно нам все это рассказать. После того, как я все это изучил, могу точно сказать, зачем понимать, как работает GC. В течение текущего дня, я думаю, вы придете к тем же самым выводам.

Рассказ будет идти от общего к частному. Я не буду сразу говорить: изучайте алгоритмы и к концу дня головы взрываются и приходит беспокойных сон. Будем разбираться от общего к частному, чтобы у всех пришло полное понимание.

Мы пишем разные программы: консольные, сервисы, web-сервисы и другие. Они все примерно одинаково работают. Но есть очень важное отличие - это стиль работы с памятью. Консольные приложения, скорее всего, работают в рамках базовой, выделенной при старте памяти. Такое приложение всю ее использует и больше ничего не запросит: запустилось и вышло. Иногда речь идет о сервисах, которые долго работают, перерабатывают память и делают это не по запросам, в отличие от сервисов ASP.NET  и WCF (которые мы вызвали, из базы что-то достали и забыли). Именно как математика - есть поток данных на вход, с которыми сервис работает и так может очень долго. Как правило, это уже совершенно другой стиль расхода памяти. В этом случае память необходимо контролировать, смотреть как она расходуется, течет - не течет.

А если это ASP.NET, то это уже третий способ управления памятью. Надо понимать, что нас вызвал внешний код, мы отработаем достаточно быстро и исчезнем. И когда этот запрос пройдет, то остаток памяти можно сбрасывать целиком. Это как пример.

Как же этим всем управлять? С точки зрения разработки Garbage Collector, с точки зрения системы менеджмента памяти у нас есть совершенно разные стили и мы должны в них идеально хорошо работать. У нас же может быть машина, на которой запустилось консольное приложение, а есть машина, на которой приложение забирает 256 Гб. Прежде всего, надо как-то классифицировать эту память.  Даже если это серверное приложение, оно расходует память по-разному на разных участках.

Как можно классифицировать? Например, по размеру. Мы можем разделить память на зоны, где есть куски разного размера. Чисто интуитивно понятно, что если мы говорим о больших структурах данных, то управлять ими надо совершенно по-другому. Потому что они тяжелые, их трудно перемещать. А маленькие, соотвественно, занимают мало места, они вместе группируются и ими управлять тяжелее. А значит, должен быть другой подход.

Если разделять по времени жизни, то тут тоже возникают идеи. Если объекты короткоживущие, то, возможно, к ним надо чаще присматриваться, чтобы побыстрее от них избавляться. Если объекты долгоживущие, то можно посмотреть на статистику. Если таких объектов по статистике много, то используются одни алгоритмы. Если мало, то можно представить, что возможно в эту область памяти можно смотреть реже.

Возможно, стоит разделить объекты по изменяемости. Если объект изменяем, то с ним нужен один подход, а если он не изменяем, константен, вылетает без модификаторов, то его стоит отнести к другой категории, потому что такие объекты обычно короткоживущие.

Или по типу данных. Можно легко предположить, что все типы, которые отнаследованы от атрибута, будут жить вечно. Или строки, которые представляют собой массив символов. К ним тоже может быть свой подход. 

Видов может быть сколько угодно и в зависимости от классификаций может оказаться, что управление памятью для конкретной классификации может быть более эффективно, если на классификации не делить.

Когда строили GC выбрали первые два вида классификаций: размер и время жизни.

Исходя из размера, есть две стратегии сборки мусора. Не одна. Самая распространенная или известная - это compact, когда происходит сжатие кучи. Про sweep знают меньше, но эта стратегия наиболее эффективна. Sweep - это уборка мусора без сжатия.

Итак, мы знаем что у нас существует два способа работы с кучам. Подумаем исходя из размеров объектов.  Если у нас объекты имеют большие размеры, то нам не выгодно делать compacting. Потому что в этом случае мы все объекты перетаскиваем на освободившиеся участки. То есть копируем их. А если объект огромен, то копировать дорого и compacting не выгоден.

Здесь удобен только sweep.  Об этом способе мы подробно поговорим позже. Как он работает: память освобождается и свободный кусок сохраняется в список свободных участков и дальше переиспользуется.
А если объекты маленькие, то наоборот - удобен compacting.

Например, у нас была куча объектов и мы потеряли ссылку на объекты через один, и получается, что занятые участки и свободные чередуются, например по 24 байта.  И может так оказаться, что такие маленькие участки нам могут больше не понадобиться, потому что дальше мы будем аллоцировать более крупные объекты. Возникнет фрагментация. Поэтому sweep с маленькими объектами не удобен, наоборот стоит сжать кучу. Отсюда у нас получается Small Objects Heap и Large Objects Heap: меньше 85 тысяч байт, либо больше или равно 85 тысячам байт.

Цифра странная, выведена из статистики, которая строится на стандартных приложениях. По этой статистике при установке порога в 85 тысяч байт все будет работать наиболее оптимизировано. 

В Small Objects Heap объекты маленькие, используем для нее compacting. Легко и быстро ими заполнять образовавшиеся пустоты. То есть, мы берем и просто сжимаем. Однако, фаза планирования для SOH может решить, что в нем более выгоден sweep. Когда речь идет о SOH там оба алгоритма прекрасно работают. Там иногда включается и sweep, но по определенным сценариям, о которых мы поговорим позже.

Но LOH использует только sweep collection, при этом пользователь может вызвать сжатие LOH вручную. Это было введено не так давно.

В отличии от SOH выравнивание не зависит от платформы и равно 8 байтами в LOH. Это значит, что в SOH зависит от платформы в первую очередь. Если 32х разрядная система, то выравнивание идет по 4м байтам, а если 64х разрядная - то по восьми. В LOH без разницы - всего 8 байт. Это сделано для внутренних оптимизаций.  

Тут возникает проблема: у нас есть хип маленьких объектов и хип больших. Они соответственно разделены. Но по факту мы всегда аллоцируем маленькие объекты. Их в любом случае будет больше, возможно миллионы, а значит их надо как-то дополнительно сегментировать. GC проходит через разные стадии: стадия планирования, стадия маркировки, сбора мусора. На 200гб памяти стадия маркировки очень дорога. Поэтому его надо как-то сегментировать.

И второй тип сегментации - это исходя из времени жизни объектов. Куча растет у нас в одном направлении. Аллокация идет с младших адресов к старшим. Берется указатель на первый свободный участок и затем он сдвигается на размер выделенного объекта и все: куча растет в одном направлении. Отсюда можно сделать вывод о том, как легко поделить на три поколения. Все, что в младших адресах - это старые объекты, где-то в середине, это первое поколения, а то, что мы выделяем сейчас - это нулевое. В последнее попадает все, что меньше 85 тысяч байт. А во-вторых, если поделить на поколения, то мы можем просматривать только последнее.

Как я уже говорил, если объекты живут долго, то туда можно реже заглядывать, чтобы запускать GC. Поэтому если мы делаем некое скользящее окно нулевого поколения по каким-то алгоритмам, мы можем его сделать таких размеров, чтобы обходить его за гарантированно короткий промежуток времени. И Microsoft гарантирует, что нулевое поколение будет собираться за какие-то миллисекунды. GC, быстро что-то сделал и дальше пошел. Именно ради этого имеется деление на поколения.

LOH имеет другую структуру. Сюда попадает все, что больше или равно 85 тысячам байт. Цифра странная, но нам полезно ее знать.  Ее можно использовать, например, чтобы определить размер для аллоцируемого массива, чтобы он не ушел в хип больших объектов. Если аллоцируете массив int-ов, то нужно грубо поделить на четыре и получится примерно 20 тысяч int-ов, туда прекрасно ляжет и не уйдет в LOH.   Также интересно, в LOH уходят массивы double от тысячи элементов. В Питере мне задавали вопрос, почему именно от тысячи элементов. Ответ примерно такой. Все эти метрики, так же как 85 тысяч байт и размер каждого поколения строятся на основе опыта. В Microsoft решили, что массивы типа double чаще всего используются в строго определенных сценариях. В обычных сценариях такие огромные массивы чисел с плавающих запятой никто не аллоцирует. Скорее всего это математика и если больше, то выгоднее всего это помещать в LOH помещать, и пусть оно там живет.

Проверить это все очень легко. Можно написать такой код - слайд 24:10 - и первый массив пойдет в нулевое, а второй - во второе поколение.  Какое еще есть деление? У нас есть два основных, которые сразу же доступны. И, на самом деле, то, что нам не доступно - деление по типу. Все мы знаем про интернированные строки. Если мы предполагаем, что какая-то строка будет часто встречаться, то ее стоит интернировать, тогда мы сэкономим на памяти.

Как они хранятся? Если строка интернирована, то она хранится как обычная строка в хипе. Но ее надо как-то найти, чтобы проверить, что точно такая же строка уже существует. Хип иногда может достигать нескольких сотен гигабайт и поиск будет очень дорогим решением. Поэтому интернированные строки хранятся отдельно. 

У каждого домена (системного или с базовым типом base domain) есть внутренняя таблица, которая нам не доступна. Например, Large Heap Handle Table. Существует два типа внутренних массивов, основанных на bucket-ах. Это массив статиков. Имеются ввиду статические члены классов, которые хранятся в массивах. У каждого домена есть ссылка на массив статиков. И дальше ячейками являются ссылки на значения. 

Что, если статик хранит какой-то ValType? У нас же, повторюсь, массивы типа object. Соответственно ValType боксятся и ссылка на забокшенный ValType хранится в этом массиве. И вы, когда работаете со статическим членом ValType, вы работаете с забокшенным значением, но по ссылке. Там все оптимизируется.  

И еще один момент - pinning handles. Это таблица запиненных элементов. Для тех случаев, когда вы пинуете объект в памяти, можете сделать это двумя путями. Первый - это через API, а второй - через ключевое слово fixed в C#. Это два совершенно разных механизма. Когда вы используете pin через API, вы пинуете, создавая GC-handle структуру и помещая эту структуру в таблицу pinning handles, которую видно на экране. 

А когда вы используете ключевое слово fixed, то объект пинуется, только если в этот момент происходит GC. То есть, если GC произошел внутри блока fixed, тогда происходит pinning. Поэтому какой вывод: если вам нужно пиновать  - используйте fixed. Потому что в этом случае вы пиновать не будете до тех пор, пока GC не попадет в этот блок.  

Это третий способ разделения. Соответственно, исходя из времени жизни. Из-за  большого количества объектов, SOH разделен на части, чтобы им было проще управлять. Заполнение SOH идет линейно, поэтому старые объекты живут в младших адресах, свежие - в старших. Старые объекты, как правило, живут долго. Чем дольше объект существует, тем больше вероятность того, что он будет существовать все время работы приложения. Поэтому существует три поколения. Нулевое поколение - это между временем создания объекта и ближайшим GC. Объектов не успевает накопится слишком много и GC успевает их быстро убрать, не залезая в остальную кучу.

Первое поколение живет между первым и вторым GC. Соответственно, для тех, кто не ушел во второе. Оптимизация какая: нулевое собирать быстро, первое - чуть подольше. Это последняя возможность GC собрать объект, прежде чем он ушел во второе, огромное, поколение. Если объект ушел во второе поколение, то, скорее всего, он будет жить долго. Туда можно редко обращаться. А первое - для объекта, который случайно ушел в первое поколение, но на самом деле он короткоживущий. Это такая оптимизация, чтобы его во втором не ловить. И второе поколение для тех, кто решил пожить подольше и если GC туда пришел, то он там надолго.

Оранжевые кубики - это руты. Руты - это точки, относительно которых, если обходить граф, то гарантированно вы обойдете все объекты, которыми пользуется программа. Если бы фаза маркировки работала на всех поколениях, то она бы работала долго. Поэтому она работает максимально на самых младших. Если мы решили, что собираем нулевое поколение, то она только там и будет работать. Поэтому есть три типа ссылок.  Первый тип - ссылка внутри одного поколения. Например, если мы с рута пришли в нулевое поколение, а дальше у нас ссылка из этого объекта, но опять в нулевое поколение. Это внутренняя ссылка.   Второй тип ссылок - это ссылка из более старшего поколения в более младшее поколение. Older-to-younger. Он характеризуется тем, что объект, на который мы ссылаемся из первого поколения нет имеет ссылки с рута в нулевом поколении. Это значит, что если мы будем маркировать только нулевое поколение, чтобы на нем GC отработал, то мы пропустим этот объект. Мы должны знать о существовании ссылки с более старшего поколения. 

Третий вид ссылок - это ссылка из младшего в старшее поколение. Для нас она не важна. Если мы собираем нулевое поколение  - она не имеет значение. При сборке более старших поколений, младшие тоже собираются. Почему? Если собираем, например, первое - оно больше, крупнее. И, поскольку, нулевое поколение собирается намного чаще, то есть высокая степень вероятности, что после сборки первого будет собрано и нулевое. И GC опять запустится. Для того, чтобы два раза не ходить за одним и тем же, пересобираются и более младшие поколения. В этом случае нам нужно знать ссылку из младшего в старшие? Нам это без разницы, она и так есть. При сборке второго поколения та же самая ситуация. С точки зрения фазы маркировки нам важны ссылки внутри поколения и ссылки с более старших на наше поколение.

Если мы находимся в нулевом поколении - как узнать о том, что на нас есть ссылка с более старшего поколения. Есть механизм, который в начале изучения начинает немного пугать. Есть такой код (см. слайд) 35:19.

Кстати, такие сценарии работы GC можно проверять таким способом: мы создаем объект, делаем GC.Collect(), отправляем его в первое поколение. Мы знаем, что он туда уйдет. Дальше создаем ссылку и тем самым фактически создаем ссылку из старшего поколения в младшее. Если дома захочется с чем-то поиграть, то с помощью метода GC.Collect() можно смоделировать такие ситуации.

Что мы здесь видим? У нас есть x, GC.Collect(), инстанс класса Foo уходит в поколение один из нулевого. И дальше x.field присваиваем new Boo(). Это значит, что объект типа Foo начинает ссылаться на новый инстанс объекта типа Boo. То есть из первого в нулевого. Это у нас older-to-younger link.

Что происходит в .NET. В месте присваивания, джиттер, то есть там не просто присваивание, а присваивание с проверкой. Эта техника называется Write Barrier и Remembered Set. В .NET она называется немного по-другому. Если у нас звезды сошлись, что нужно запомнить эту ссылку, то мы запоминаем ее во внутренней структуре джита.

Что это за условие? Значение - это ссылка на экземпляр .NET класса. Точка присваивания находится в управляемой куче и имеет более старшее поколение, чем адрес присваиваемого объекта. Когда мы делаем вот так (см. слайд 37:29), джиттер дополнительно проверяет, что слева поколение старше, чем справа. Если старше, то он запоминает адреса во внутренних структурах, убеждается, что с левой части на правую есть ссылка. Это нужно для дальнейшей сборки мусора. На фазе маркировки отмечается выбранное поколение и если у нас есть ссылки в Remembered Set, если мы запомнили, что где-то сохраняли ссылку из первого в нулевое поколение, они тоже становятся корнями, чтобы пройти маркировку. Но хип получается в итоге огромный и становится страшновато.

Поэтому используется более оптимизированный способ. Он называется механизм карточного стола. Знания об этом механизме не так распространены. Как он работает? Если взять адресное пространство всего огромного хипа, весь кусок памяти, то сбоку есть карточный стол. Это, грубо говоря, массив чисел. Где каждый бит массива отвечает за определенный диапазон памяти. Если бит выставлен в единицу, значит в этом диапазоне памяти есть ссылка на младшее поколение. То есть это массив признаков ссылок на младшее поколение. См. слайд - 40:12 

У нас есть память, внизу карточный стол. У нас появилась ссылка, слева на право. Это значит, что бит должен быть выставлен в единицу. Потому что от более старшего поколения пошла ссылка в более младшее.   Каждый бит карточного стола отвечает за 128 байт в x86 и за 256 байт в x64. Это, по сути, 32 машинных слова. Машинное слово - это то, с чем работает процессор.

Если учесть, что каждый пустой объект, максимально маленький (например, new Object) занимает четыре машинных слова в среднем, то получается, что один бит карточного стола перекрывает десять объектов. И если хотя бы с одного из них есть ссылка в младшее поколение, то GC должен при обходе в фазе маркировки зайти по этому адресу и просмотреть все десять объектов и найти те, которые ссылаются на младшее поколение.  
Один байт перекрывает уже 1,2 КБ оперативной памяти. Или 80 объектов. Четыре байта - 320 объектов. Это x86 архитектура. Получается жирновато, если ссылка появилась. 

Как это работает. Можно посмотреть код, который будет вызван при присваивании (см. слайд 43:24) по этому адресу на github. Там ассемблеровский код, он достаточно простой, разобраться в нем легко. Есть много комментариев, гораздо больше, чем кода.

Реализация сильно зависит от особенностей. У нас есть Workstation GC, есть серверный GC. У Workstation есть две версии: до и после роста кучи. Как следствие, перемещается gen_1 gen_0. И Server GC: есть несколько хипов для SOH и несколько для LOH. Там свои реализации этих методов присваивания, потому что придется параметризовать для какой кучи идет вызов. А так он просто генерирует ставку для новой кучи и все хорошо. Плюс две реализации под x64. Если смотреть базовую, то будет примерно так (см. слайд 44:36). Регистр RCX - это адрес filed. Адрес таргета, куда мы присваиваем. RDX - это ссылка на объект. Когда мы присваивали, должна быть составлена эта инструкция и больше ничего. Но на самом деле нет. Присвоили и дальше этим кодом мы проверяем, находится ли правая часть присваивания внутри эфемерного сегмента (gen_0, gen_1). И если находится, то мы берем карточный стол, делим на 2048, получаем адрес ячейки и если флаг не выставлен, то выставить.

Здесь есть две особенности. Первая  - почему просто не выставить? Это будет очень долго. Операция записи намного дольше, чем чтения. Чтение происходит из кеша, а чтобы записать надо записать кроме кеша еще и в оперативную память. Поэтому их проверяем. Интересна процедура выставления флага. Он выставляется сразу же 0FF. То есть мы выставляем не один флаг, а сразу группой. Почему? Когда мы будем дальше проверять ссылку из старшего поколения в младшее, нам побитово будет долго проверять. Проще сразу словами делать проверку. Вместо того, чтобы смотреть, на каком бите ссылка и какие 2 КБ смотреть, все работает проще, система оперирует более значительными диапазонами.  

Код, получается, проверяет только поколение object, но не target. Target не интересует. Мы проверяем только то, что мы попали в нулевое или первое поколение. В любом этом случае выставляется бит в карточном столе. Когда мы проверяем нулевое поколение, будем проходится по карточному столу, который относится и к первому, и ко второму поколению. Нас устроит, что биты выставлены. Если первое поколение будем просматривать с нулевым, собирать там мусор и у первого и второго, то мы будем просматривать карточный стол второго поколения. Там тоже эти биты будут выставлены. Поэтому мы левую часть смотрим, и не имеет значения первого или второго поколения. Дальше фильтрация уже идет на стадии проверки.

Однако, карточный стол в случае большого хипа (у LOH он может быть феерических размеров) тоже будет огромным. И по нему точно так же будет идти сканирование. Мы собираем нулевое поколение и должны уложиться в несколько миллисекунд, а у нас хип в несколько сотен ГБ. Например, это сервер. Карточный стол придется сканировать весь, а это долго. Выход - двухуровневый карточный стол. Называется это Cards Bundle Table. Это еще один массив, где бит отвечает за 32 слова карт. Этот массив оперирует огромными диапазонами. Получается, 1 бит Cards Bundle Table отвечает за 128 Кб на x86 и за 256 Кб на x64. Одна ячейка  - 4 байта, это 8 Мб карт целевой памяти.

Когда мы будем делать GC, собирая нулевое поколение, надо посмотреть, что с первого и второго есть что-то полезное и далее мы уходим в Cards Bundle Table. Сканиурем, и если где-то не ноль, то переходим на карточный стол, в соответствующий его диапазон и ищем ненулевую ячейку. И потом уже переходим в нужный диапазон памяти и сканиурем объекты, которые там находятся, в поисках ссылки со старшего на младшее поколение. И только тогда мы эту ссылку добавляем в руты и маркируем все объекты, на которые эта ссылка ведет.  

Есть маленькая оптимизация для Windows. Эта система построена, в первую очередь, на архитектуре x86, где используются механизмы вирутализации памяти процессора, которая основана на страницах памяти. Она поделена на зоны, на странички. Можно выставить флаг MEM_WRITE_WATCH. Это означает, что если кто-то будет писать по заданному диапазону, то можно подписаться на обновления. Мы сделали массив и если туда кто-то будет писать, у нас будет дергаться метод из winapi. Почему мы не видим этого когда в ассемблеровском методе расстановки  карт? Когда мы записываем, выставляя карты, Windows получает нотификацию от страницы, куда мы пишем, и исходя из этого проставляет бит в Cards Bundle Table.

Базовый вывод, который можно сделать уже сейчас, основываясь на карточных столах, что если вы хотите, чтобы GC протекал быстро и как по маслу, не стоит делать ссылок из старших поколений. Не надо делать вечноживущие массивы, аллоцировать объекты и ссылки на них складывать в эти древние массивы. Но если вы так делаете, надо контролировать, чтобы эти массивы располагались рядом, чтобы их аллоцировать друг за другом. Не распределять их по памяти. Самое неудачное, что можно сделать - это иметь кучу объектов старшего поколения и по какой-то причине выставить ссылки на младшее поколение, но не группой, а вразброс через всю память. Это самый тяжелый сценарий, потому что карточный стол будет забит единицами. А GC, собирая нулевое поколение, будет вынужден проходить все второе, все первое и искать, что там добавлено. Если вы делаете ссылку из старших поколений в младшие, то необходимо эти ссылки группировать: массив, который ссылается на объект младшего поколения. Поскольку это массив, который ссылается на объекты младшего поколения, все ячейки рядом и в карточном столе в идеале это будет просто единица. Дальше мы будем изучать более подробно.
